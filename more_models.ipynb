{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Data Viz. \n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from calendar import monthrange\n",
    "from calendar import month_name\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "from matplotlib import rcParams\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "RSEED=42\n",
    "import datetime, time, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breath_id</th>\n",
       "      <th>R</th>\n",
       "      <th>C</th>\n",
       "      <th>time_step</th>\n",
       "      <th>u_in</th>\n",
       "      <th>u_out</th>\n",
       "      <th>pressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083334</td>\n",
       "      <td>0</td>\n",
       "      <td>5.837492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>0.033652</td>\n",
       "      <td>18.383041</td>\n",
       "      <td>0</td>\n",
       "      <td>5.907794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>0.067514</td>\n",
       "      <td>22.509278</td>\n",
       "      <td>0</td>\n",
       "      <td>7.876254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>0.101542</td>\n",
       "      <td>22.808822</td>\n",
       "      <td>0</td>\n",
       "      <td>11.742872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>0.135756</td>\n",
       "      <td>25.355850</td>\n",
       "      <td>0</td>\n",
       "      <td>12.234987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6035995</th>\n",
       "      <td>6035996</td>\n",
       "      <td>125749</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>2.504603</td>\n",
       "      <td>1.489714</td>\n",
       "      <td>1</td>\n",
       "      <td>3.869032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6035996</th>\n",
       "      <td>6035997</td>\n",
       "      <td>125749</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>2.537961</td>\n",
       "      <td>1.488497</td>\n",
       "      <td>1</td>\n",
       "      <td>3.869032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6035997</th>\n",
       "      <td>6035998</td>\n",
       "      <td>125749</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>2.571408</td>\n",
       "      <td>1.558978</td>\n",
       "      <td>1</td>\n",
       "      <td>3.798729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6035998</th>\n",
       "      <td>6035999</td>\n",
       "      <td>125749</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>2.604744</td>\n",
       "      <td>1.272663</td>\n",
       "      <td>1</td>\n",
       "      <td>4.079938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6035999</th>\n",
       "      <td>6036000</td>\n",
       "      <td>125749</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>2.638017</td>\n",
       "      <td>1.482739</td>\n",
       "      <td>1</td>\n",
       "      <td>3.869032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6036000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  breath_id   R   C  time_step       u_in  u_out   pressure\n",
       "0              1          1  20  50   0.000000   0.083334      0   5.837492\n",
       "1              2          1  20  50   0.033652  18.383041      0   5.907794\n",
       "2              3          1  20  50   0.067514  22.509278      0   7.876254\n",
       "3              4          1  20  50   0.101542  22.808822      0  11.742872\n",
       "4              5          1  20  50   0.135756  25.355850      0  12.234987\n",
       "...          ...        ...  ..  ..        ...        ...    ...        ...\n",
       "6035995  6035996     125749  50  10   2.504603   1.489714      1   3.869032\n",
       "6035996  6035997     125749  50  10   2.537961   1.488497      1   3.869032\n",
       "6035997  6035998     125749  50  10   2.571408   1.558978      1   3.798729\n",
       "6035998  6035999     125749  50  10   2.604744   1.272663      1   4.079938\n",
       "6035999  6036000     125749  50  10   2.638017   1.482739      1   3.869032\n",
       "\n",
       "[6036000 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/train.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d5/ywbj67kx54n4fq9j7nf3v4wh0000gn/T/ipykernel_48764/1413260000.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['vol'] = df['time_step'] * df['u_in']\n",
      "/var/folders/d5/ywbj67kx54n4fq9j7nf3v4wh0000gn/T/ipykernel_48764/1413260000.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['vol'] = df.query('u_out==0').groupby('breath_id')['vol'].cumsum()\n",
      "/var/folders/d5/ywbj67kx54n4fq9j7nf3v4wh0000gn/T/ipykernel_48764/1413260000.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['rtime']=df['time_step'].apply(lambda x: round(x,3))\n",
      "/var/folders/d5/ywbj67kx54n4fq9j7nf3v4wh0000gn/T/ipykernel_48764/1413260000.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['step_id']=df.id.apply(lambda x: x%80)\n"
     ]
    }
   ],
   "source": [
    "df['vol'] = df['time_step'] * df['u_in']\n",
    "df['vol'] = df.query('u_out==0').groupby('breath_id')['vol'].cumsum()\n",
    "df['rtime']=df['time_step'].apply(lambda x: round(x,3))\n",
    "df.query('id%80==2')\n",
    "df['step_id']=df.id.apply(lambda x: x%80)\n",
    "df=df.query('u_out==0')\n",
    "df['u_in_cumsum'] = (df['u_in']).groupby(df['breath_id']).cumsum()\n",
    "df['minus_one']=-1.0\n",
    "df['plus_one']=1.0\n",
    "df['exponent']=(df['minus_one']*df['time_step'])/(df['R']*df['C'])\n",
    "df['factor']=np.exp(df['exponent'])\n",
    "df['vf']=(df['u_in_cumsum']*df['R'])/df['factor']\n",
    "df['vt']=0\n",
    "df.loc[df['time_step'] != 0, 'vt']=df['vol']/(df['C']*(df['minus_one']*df['factor']+df['plus_one']))\n",
    "df['v']=df['vf']+df['vt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v</th>\n",
       "      <th>u_in_cumsum</th>\n",
       "      <th>vol</th>\n",
       "      <th>pressure</th>\n",
       "      <th>u_in</th>\n",
       "      <th>R</th>\n",
       "      <th>C</th>\n",
       "      <th>time_step</th>\n",
       "      <th>step_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.666680</td>\n",
       "      <td>0.083334</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.837492</td>\n",
       "      <td>0.083334</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>737.006954</td>\n",
       "      <td>18.466375</td>\n",
       "      <td>0.618632</td>\n",
       "      <td>5.907794</td>\n",
       "      <td>18.383041</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>0.033652</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1453.034477</td>\n",
       "      <td>40.975653</td>\n",
       "      <td>2.138333</td>\n",
       "      <td>7.876254</td>\n",
       "      <td>22.509278</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>0.067514</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2153.211108</td>\n",
       "      <td>63.784476</td>\n",
       "      <td>4.454391</td>\n",
       "      <td>11.742872</td>\n",
       "      <td>22.808822</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>0.101542</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2946.481672</td>\n",
       "      <td>89.140326</td>\n",
       "      <td>7.896588</td>\n",
       "      <td>12.234987</td>\n",
       "      <td>25.355850</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>0.135756</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6035945</th>\n",
       "      <td>15962.475671</td>\n",
       "      <td>238.890288</td>\n",
       "      <td>66.643100</td>\n",
       "      <td>29.459013</td>\n",
       "      <td>1.869367</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>0.834147</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6035946</th>\n",
       "      <td>16025.086384</td>\n",
       "      <td>241.044703</td>\n",
       "      <td>68.512214</td>\n",
       "      <td>29.107502</td>\n",
       "      <td>2.154414</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>0.867574</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6035947</th>\n",
       "      <td>16010.376008</td>\n",
       "      <td>242.349137</td>\n",
       "      <td>69.687402</td>\n",
       "      <td>29.880825</td>\n",
       "      <td>1.304434</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>0.900917</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6035948</th>\n",
       "      <td>16046.588564</td>\n",
       "      <td>244.082966</td>\n",
       "      <td>71.307334</td>\n",
       "      <td>29.388710</td>\n",
       "      <td>1.733830</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>0.934309</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6035949</th>\n",
       "      <td>16011.579966</td>\n",
       "      <td>245.041693</td>\n",
       "      <td>72.235134</td>\n",
       "      <td>30.091732</td>\n",
       "      <td>0.958726</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>0.967743</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2290968 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    v  u_in_cumsum        vol   pressure       u_in   R   C  \\\n",
       "0            1.666680     0.083334   0.000000   5.837492   0.083334  20  50   \n",
       "1          737.006954    18.466375   0.618632   5.907794  18.383041  20  50   \n",
       "2         1453.034477    40.975653   2.138333   7.876254  22.509278  20  50   \n",
       "3         2153.211108    63.784476   4.454391  11.742872  22.808822  20  50   \n",
       "4         2946.481672    89.140326   7.896588  12.234987  25.355850  20  50   \n",
       "...               ...          ...        ...        ...        ...  ..  ..   \n",
       "6035945  15962.475671   238.890288  66.643100  29.459013   1.869367  50  10   \n",
       "6035946  16025.086384   241.044703  68.512214  29.107502   2.154414  50  10   \n",
       "6035947  16010.376008   242.349137  69.687402  29.880825   1.304434  50  10   \n",
       "6035948  16046.588564   244.082966  71.307334  29.388710   1.733830  50  10   \n",
       "6035949  16011.579966   245.041693  72.235134  30.091732   0.958726  50  10   \n",
       "\n",
       "         time_step  step_id  \n",
       "0         0.000000        1  \n",
       "1         0.033652        2  \n",
       "2         0.067514        3  \n",
       "3         0.101542        4  \n",
       "4         0.135756        5  \n",
       "...            ...      ...  \n",
       "6035945   0.834147       26  \n",
       "6035946   0.867574       27  \n",
       "6035947   0.900917       28  \n",
       "6035948   0.934309       29  \n",
       "6035949   0.967743       30  \n",
       "\n",
       "[2290968 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols=['v','u_in_cumsum','vol','pressure', 'u_in', 'R', 'C', 'time_step', 'step_id']\n",
    "red_df=df[cols]\n",
    "red_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1603677, 8)\n",
      "y_train shape: (1603677,)\n",
      "X_test shape: (687291, 8)\n",
      "y_test shape: (687291,)\n"
     ]
    }
   ],
   "source": [
    "#train test split\n",
    "target=\"pressure\"\n",
    "X = red_df.drop(target, axis=1)\n",
    "y = red_df.loc[:,target].values\n",
    "#y = df_dmy[target]\n",
    "#y = np.array(df.pop(\"target\"))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .3, random_state=RSEED)#, stratify=False)\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('y_test shape:', y_test.shape)\n",
    "\n",
    "\n",
    "scaler= StandardScaler()\n",
    "#num_list = list(X_train.columns[X_train.dtypes!=object])\n",
    "col_names = ['v', 'u_in_cumsum', 'vol', 'u_in',\t'R', 'C']\n",
    "X_train_num=X_train[col_names].copy()\n",
    "\n",
    "X_train[col_names] = scaler.fit_transform(X_train[col_names])\n",
    "X_test[col_names] = scaler.transform(X_test[col_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With this command you can clear any logs from previous runs\n",
    "# If you want to compare different runs you can skip this cell \n",
    "!rm -rf my_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./my_logs_second'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define path for new directory \n",
    "root_logdir = os.path.join(os.curdir, \"my_logs_second\")\n",
    "root_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for creating a new folder for each run\n",
    "def get_run_logdir():\n",
    "    run_id = time.strftime('run_%d_%m_%Y-%H_%M_%S')\n",
    "    return os.path.join(root_logdir, run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./my_logs_second/run_21_04_2022-17_39_34'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_logdir = get_run_logdir()\n",
    "run_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function for using callbacks; \"name\" should be the name of the model you use\n",
    "def get_callbacks(name):\n",
    "    return tf.keras.callbacks.TensorBoard(run_logdir+name, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-21 17:56:28.319502: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-21 17:56:28.343518: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "#choosing the variable and normalizing it\n",
    "#col_var = ['v', 'u_in_cumsum', 'vol', 'u_in', 'R', 'C']\n",
    "new_var = np.array(X_train)\n",
    "\n",
    "new_all_normalizer = preprocessing.Normalization(input_shape = [8,], axis = None)\n",
    "new_all_normalizer.adapt(new_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a model\n",
    "def build_and_compile_model7(norm):\n",
    "    model = keras.Sequential([\n",
    "        norm,\n",
    "        layers.Dense(80, activation='selu'),\n",
    "        layers.Dense(80, activation='selu'),\n",
    "        layers.Dense(80, activation='selu'),\n",
    "        layers.Dense(80, activation='selu'),\n",
    "        layers.Dense(80, activation='selu'),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    model.compile(loss='mae',\n",
    "                  metrics='mae',\n",
    "                  optimizer=tf.keras.optimizers.Adam(0.01))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building the model using single input\n",
    "dnn_new_all_model7 = build_and_compile_model7(new_all_normalizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization_1 (Normalizat  (None, 8)                3         \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " dense (Dense)               (None, 80)                720       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,724\n",
      "Trainable params: 26,721\n",
      "Non-trainable params: 3\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#model summary\n",
    "dnn_new_all_model7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-21 18:01:06.150926: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2566/2566 [==============================] - ETA: 0s - loss: 2.1924 - mae: 2.1924"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-21 18:01:52.442205: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2566/2566 [==============================] - 53s 19ms/step - loss: 2.1924 - mae: 2.1924 - val_loss: 1.7577 - val_mae: 1.7577\n",
      "Epoch 2/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.7019 - mae: 1.7019 - val_loss: 1.6101 - val_mae: 1.6101\n",
      "Epoch 3/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.5950 - mae: 1.5950 - val_loss: 1.6085 - val_mae: 1.6085\n",
      "Epoch 4/500\n",
      "2566/2566 [==============================] - 49s 19ms/step - loss: 1.5587 - mae: 1.5587 - val_loss: 1.6265 - val_mae: 1.6265\n",
      "Epoch 5/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.5292 - mae: 1.5292 - val_loss: 1.5209 - val_mae: 1.5209\n",
      "Epoch 6/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.4934 - mae: 1.4934 - val_loss: 1.4656 - val_mae: 1.4656\n",
      "Epoch 7/500\n",
      "2566/2566 [==============================] - 50s 20ms/step - loss: 1.4723 - mae: 1.4723 - val_loss: 1.4819 - val_mae: 1.4819\n",
      "Epoch 8/500\n",
      "2566/2566 [==============================] - 49s 19ms/step - loss: 1.4513 - mae: 1.4513 - val_loss: 1.3988 - val_mae: 1.3988\n",
      "Epoch 9/500\n",
      "2566/2566 [==============================] - 49s 19ms/step - loss: 1.4319 - mae: 1.4319 - val_loss: 1.4849 - val_mae: 1.4849\n",
      "Epoch 10/500\n",
      "2566/2566 [==============================] - 49s 19ms/step - loss: 1.4204 - mae: 1.4204 - val_loss: 1.3525 - val_mae: 1.3525\n",
      "Epoch 11/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.4067 - mae: 1.4067 - val_loss: 1.3757 - val_mae: 1.3757\n",
      "Epoch 12/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.4010 - mae: 1.4010 - val_loss: 1.4196 - val_mae: 1.4196\n",
      "Epoch 13/500\n",
      "2566/2566 [==============================] - 349s 136ms/step - loss: 1.4231 - mae: 1.4231 - val_loss: 1.6195 - val_mae: 1.6195\n",
      "Epoch 14/500\n",
      "2566/2566 [==============================] - 672s 262ms/step - loss: 1.5345 - mae: 1.5345 - val_loss: 1.4780 - val_mae: 1.4780\n",
      "Epoch 15/500\n",
      "2566/2566 [==============================] - 45s 18ms/step - loss: 1.4308 - mae: 1.4308 - val_loss: 1.4035 - val_mae: 1.4035\n",
      "Epoch 16/500\n",
      "2566/2566 [==============================] - 344s 134ms/step - loss: 1.3798 - mae: 1.3798 - val_loss: 1.4193 - val_mae: 1.4193\n",
      "Epoch 17/500\n",
      "2566/2566 [==============================] - 344s 134ms/step - loss: 1.3508 - mae: 1.3508 - val_loss: 1.2630 - val_mae: 1.2630\n",
      "Epoch 18/500\n",
      "2566/2566 [==============================] - 343s 134ms/step - loss: 1.3439 - mae: 1.3439 - val_loss: 1.3930 - val_mae: 1.3930\n",
      "Epoch 19/500\n",
      "2566/2566 [==============================] - 344s 134ms/step - loss: 1.5057 - mae: 1.5057 - val_loss: 1.4967 - val_mae: 1.4967\n",
      "Epoch 20/500\n",
      "2566/2566 [==============================] - 44s 17ms/step - loss: 1.7028 - mae: 1.7028 - val_loss: 1.5878 - val_mae: 1.5878\n",
      "Epoch 21/500\n",
      "2566/2566 [==============================] - 44s 17ms/step - loss: 1.5832 - mae: 1.5832 - val_loss: 1.4962 - val_mae: 1.4962\n",
      "Epoch 22/500\n",
      "2566/2566 [==============================] - 43s 17ms/step - loss: 1.4705 - mae: 1.4705 - val_loss: 1.3670 - val_mae: 1.3670\n",
      "Epoch 23/500\n",
      "2566/2566 [==============================] - 43s 17ms/step - loss: 1.4208 - mae: 1.4208 - val_loss: 1.4110 - val_mae: 1.4110\n",
      "Epoch 24/500\n",
      "2566/2566 [==============================] - 44s 17ms/step - loss: 1.3923 - mae: 1.3923 - val_loss: 1.3763 - val_mae: 1.3763\n",
      "Epoch 25/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.3745 - mae: 1.3745 - val_loss: 1.2802 - val_mae: 1.2802\n",
      "Epoch 26/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.3525 - mae: 1.3525 - val_loss: 1.3637 - val_mae: 1.3637\n",
      "Epoch 27/500\n",
      "2566/2566 [==============================] - 49s 19ms/step - loss: 1.3272 - mae: 1.3272 - val_loss: 1.2683 - val_mae: 1.2683\n",
      "Epoch 28/500\n",
      "2566/2566 [==============================] - 46s 18ms/step - loss: 1.3171 - mae: 1.3171 - val_loss: 1.2753 - val_mae: 1.2753\n",
      "Epoch 29/500\n",
      "2566/2566 [==============================] - 46s 18ms/step - loss: 1.2996 - mae: 1.2996 - val_loss: 1.3613 - val_mae: 1.3613\n",
      "Epoch 30/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.2939 - mae: 1.2939 - val_loss: 1.2211 - val_mae: 1.2211\n",
      "Epoch 31/500\n",
      "2566/2566 [==============================] - 46s 18ms/step - loss: 1.2851 - mae: 1.2851 - val_loss: 1.3540 - val_mae: 1.3540\n",
      "Epoch 32/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.2823 - mae: 1.2823 - val_loss: 1.3808 - val_mae: 1.3808\n",
      "Epoch 33/500\n",
      "2566/2566 [==============================] - 46s 18ms/step - loss: 1.3007 - mae: 1.3007 - val_loss: 1.3040 - val_mae: 1.3040\n",
      "Epoch 34/500\n",
      "2566/2566 [==============================] - 46s 18ms/step - loss: 1.6216 - mae: 1.6216 - val_loss: 1.6635 - val_mae: 1.6635\n",
      "Epoch 35/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.6281 - mae: 1.6281 - val_loss: 1.5640 - val_mae: 1.5640\n",
      "Epoch 36/500\n",
      "2566/2566 [==============================] - 46s 18ms/step - loss: 1.5039 - mae: 1.5039 - val_loss: 1.5329 - val_mae: 1.5329\n",
      "Epoch 37/500\n",
      "2566/2566 [==============================] - 45s 18ms/step - loss: 1.5539 - mae: 1.5539 - val_loss: 1.5572 - val_mae: 1.5572\n",
      "Epoch 38/500\n",
      "2566/2566 [==============================] - 347s 135ms/step - loss: 1.4734 - mae: 1.4734 - val_loss: 1.4202 - val_mae: 1.4202\n",
      "Epoch 39/500\n",
      "2566/2566 [==============================] - 223s 87ms/step - loss: 1.4288 - mae: 1.4287 - val_loss: 1.4633 - val_mae: 1.4633\n",
      "Epoch 40/500\n",
      "2566/2566 [==============================] - 50s 19ms/step - loss: 1.3731 - mae: 1.3731 - val_loss: 1.3393 - val_mae: 1.3393\n",
      "Epoch 41/500\n",
      "2566/2566 [==============================] - 53s 21ms/step - loss: 1.3551 - mae: 1.3551 - val_loss: 1.2725 - val_mae: 1.2725\n",
      "Epoch 42/500\n",
      "2566/2566 [==============================] - 45s 18ms/step - loss: 1.5013 - mae: 1.5013 - val_loss: 1.5985 - val_mae: 1.5985\n",
      "Epoch 43/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.4377 - mae: 1.4377 - val_loss: 1.3340 - val_mae: 1.3340\n",
      "Epoch 44/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.3664 - mae: 1.3664 - val_loss: 1.2933 - val_mae: 1.2933\n",
      "Epoch 45/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.4248 - mae: 1.4248 - val_loss: 2.1118 - val_mae: 2.1118\n",
      "Epoch 46/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.7101 - mae: 1.7101 - val_loss: 1.5378 - val_mae: 1.5378\n",
      "Epoch 47/500\n",
      "2566/2566 [==============================] - 46s 18ms/step - loss: 1.5594 - mae: 1.5594 - val_loss: 1.4112 - val_mae: 1.4112\n",
      "Epoch 48/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.4733 - mae: 1.4733 - val_loss: 1.3861 - val_mae: 1.3861\n",
      "Epoch 49/500\n",
      "2566/2566 [==============================] - 49s 19ms/step - loss: 1.4099 - mae: 1.4099 - val_loss: 1.3444 - val_mae: 1.3444\n",
      "Epoch 50/500\n",
      "2566/2566 [==============================] - 49s 19ms/step - loss: 1.4224 - mae: 1.4224 - val_loss: 1.4289 - val_mae: 1.4289\n",
      "Epoch 51/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.4037 - mae: 1.4037 - val_loss: 1.3504 - val_mae: 1.3504\n",
      "Epoch 52/500\n",
      "2566/2566 [==============================] - 46s 18ms/step - loss: 1.4355 - mae: 1.4355 - val_loss: 1.3810 - val_mae: 1.3810\n",
      "Epoch 53/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.3751 - mae: 1.3751 - val_loss: 1.3240 - val_mae: 1.3240\n",
      "Epoch 54/500\n",
      "2566/2566 [==============================] - 46s 18ms/step - loss: 1.3431 - mae: 1.3431 - val_loss: 1.3992 - val_mae: 1.3992\n",
      "Epoch 55/500\n",
      "2566/2566 [==============================] - 49s 19ms/step - loss: 1.3582 - mae: 1.3582 - val_loss: 1.3921 - val_mae: 1.3921\n",
      "Epoch 56/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.3249 - mae: 1.3249 - val_loss: 1.3630 - val_mae: 1.3630\n",
      "Epoch 57/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.3236 - mae: 1.3236 - val_loss: 1.2998 - val_mae: 1.2998\n",
      "Epoch 58/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.2998 - mae: 1.2998 - val_loss: 1.3227 - val_mae: 1.3227\n",
      "Epoch 59/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.3028 - mae: 1.3028 - val_loss: 1.2668 - val_mae: 1.2668\n",
      "Epoch 60/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.2873 - mae: 1.2873 - val_loss: 1.2421 - val_mae: 1.2421\n",
      "Epoch 61/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.2908 - mae: 1.2908 - val_loss: 1.3141 - val_mae: 1.3141\n",
      "Epoch 62/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.2832 - mae: 1.2832 - val_loss: 1.2580 - val_mae: 1.2580\n",
      "Epoch 63/500\n",
      "2566/2566 [==============================] - 49s 19ms/step - loss: 1.2989 - mae: 1.2989 - val_loss: 1.2732 - val_mae: 1.2732\n",
      "Epoch 64/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.2715 - mae: 1.2715 - val_loss: 1.2555 - val_mae: 1.2555\n",
      "Epoch 65/500\n",
      "2566/2566 [==============================] - 49s 19ms/step - loss: 1.2771 - mae: 1.2771 - val_loss: 1.3133 - val_mae: 1.3133\n",
      "Epoch 66/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.2706 - mae: 1.2706 - val_loss: 1.3809 - val_mae: 1.3809\n",
      "Epoch 67/500\n",
      "2566/2566 [==============================] - 49s 19ms/step - loss: 1.2600 - mae: 1.2600 - val_loss: 1.2844 - val_mae: 1.2844\n",
      "Epoch 68/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.2623 - mae: 1.2623 - val_loss: 1.2130 - val_mae: 1.2130\n",
      "Epoch 69/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.2549 - mae: 1.2549 - val_loss: 1.5110 - val_mae: 1.5110\n",
      "Epoch 70/500\n",
      "2566/2566 [==============================] - 49s 19ms/step - loss: 1.2568 - mae: 1.2568 - val_loss: 1.3333 - val_mae: 1.3333\n",
      "Epoch 71/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 3.3013 - mae: 3.3013 - val_loss: 2.2479 - val_mae: 2.2479\n",
      "Epoch 72/500\n",
      "2566/2566 [==============================] - 73s 28ms/step - loss: 2.0809 - mae: 2.0809 - val_loss: 1.9438 - val_mae: 1.9438\n",
      "Epoch 73/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.9324 - mae: 1.9324 - val_loss: 1.8967 - val_mae: 1.8967\n",
      "Epoch 74/500\n",
      "2566/2566 [==============================] - 49s 19ms/step - loss: 1.8329 - mae: 1.8329 - val_loss: 2.0393 - val_mae: 2.0393\n",
      "Epoch 75/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.7389 - mae: 1.7389 - val_loss: 1.7202 - val_mae: 1.7202\n",
      "Epoch 76/500\n",
      "2566/2566 [==============================] - 49s 19ms/step - loss: 2.3067 - mae: 2.3067 - val_loss: 2.2404 - val_mae: 2.2404\n",
      "Epoch 77/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.8854 - mae: 1.8854 - val_loss: 1.7135 - val_mae: 1.7135\n",
      "Epoch 78/500\n",
      "2566/2566 [==============================] - 49s 19ms/step - loss: 1.7142 - mae: 1.7142 - val_loss: 1.6454 - val_mae: 1.6454\n",
      "Epoch 79/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.9131 - mae: 1.9131 - val_loss: 1.7950 - val_mae: 1.7950\n",
      "Epoch 80/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.7178 - mae: 1.7178 - val_loss: 1.7431 - val_mae: 1.7431\n",
      "Epoch 81/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.6626 - mae: 1.6626 - val_loss: 1.6282 - val_mae: 1.6282\n",
      "Epoch 82/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.6352 - mae: 1.6352 - val_loss: 1.6060 - val_mae: 1.6060\n",
      "Epoch 83/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.6103 - mae: 1.6103 - val_loss: 1.5759 - val_mae: 1.5759\n",
      "Epoch 84/500\n",
      "2566/2566 [==============================] - 49s 19ms/step - loss: 1.5879 - mae: 1.5879 - val_loss: 1.5279 - val_mae: 1.5279\n",
      "Epoch 85/500\n",
      "2566/2566 [==============================] - 49s 19ms/step - loss: 1.5704 - mae: 1.5704 - val_loss: 1.5405 - val_mae: 1.5405\n",
      "Epoch 86/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.5553 - mae: 1.5553 - val_loss: 1.5154 - val_mae: 1.5154\n",
      "Epoch 87/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.5418 - mae: 1.5418 - val_loss: 1.5017 - val_mae: 1.5017\n",
      "Epoch 88/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.5299 - mae: 1.5299 - val_loss: 1.5023 - val_mae: 1.5023\n",
      "Epoch 89/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.5189 - mae: 1.5189 - val_loss: 1.5111 - val_mae: 1.5111\n",
      "Epoch 90/500\n",
      "2566/2566 [==============================] - 49s 19ms/step - loss: 1.5049 - mae: 1.5049 - val_loss: 1.4844 - val_mae: 1.4844\n",
      "Epoch 91/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.5465 - mae: 1.5465 - val_loss: 1.4792 - val_mae: 1.4792\n",
      "Epoch 92/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.4876 - mae: 1.4876 - val_loss: 1.4724 - val_mae: 1.4724\n",
      "Epoch 93/500\n",
      "2566/2566 [==============================] - 49s 19ms/step - loss: 1.4776 - mae: 1.4776 - val_loss: 1.5359 - val_mae: 1.5359\n",
      "Epoch 94/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.7246 - mae: 1.7246 - val_loss: 1.5222 - val_mae: 1.5222\n",
      "Epoch 95/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.5246 - mae: 1.5246 - val_loss: 1.4452 - val_mae: 1.4452\n",
      "Epoch 96/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.4927 - mae: 1.4927 - val_loss: 1.5603 - val_mae: 1.5603\n",
      "Epoch 97/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.4628 - mae: 1.4628 - val_loss: 1.4151 - val_mae: 1.4151\n",
      "Epoch 98/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.4452 - mae: 1.4452 - val_loss: 1.4174 - val_mae: 1.4174\n",
      "Epoch 99/500\n",
      "2566/2566 [==============================] - 46s 18ms/step - loss: 1.4251 - mae: 1.4251 - val_loss: 1.5373 - val_mae: 1.5373\n",
      "Epoch 100/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.4140 - mae: 1.4140 - val_loss: 1.4153 - val_mae: 1.4153\n",
      "Epoch 101/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.3999 - mae: 1.3999 - val_loss: 1.3684 - val_mae: 1.3684\n",
      "Epoch 102/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.3916 - mae: 1.3916 - val_loss: 1.3608 - val_mae: 1.3608\n",
      "Epoch 103/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.3852 - mae: 1.3852 - val_loss: 1.3465 - val_mae: 1.3465\n",
      "Epoch 104/500\n",
      "2566/2566 [==============================] - 46s 18ms/step - loss: 1.3750 - mae: 1.3750 - val_loss: 1.3895 - val_mae: 1.3895\n",
      "Epoch 105/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.3644 - mae: 1.3644 - val_loss: 1.3090 - val_mae: 1.3090\n",
      "Epoch 106/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.3793 - mae: 1.3793 - val_loss: 1.3254 - val_mae: 1.3254\n",
      "Epoch 107/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.4189 - mae: 1.4189 - val_loss: 1.3804 - val_mae: 1.3804\n",
      "Epoch 108/500\n",
      "2566/2566 [==============================] - 46s 18ms/step - loss: 1.3953 - mae: 1.3953 - val_loss: 1.5264 - val_mae: 1.5264\n",
      "Epoch 109/500\n",
      "2566/2566 [==============================] - 46s 18ms/step - loss: 1.3756 - mae: 1.3756 - val_loss: 1.3348 - val_mae: 1.3348\n",
      "Epoch 110/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.3706 - mae: 1.3706 - val_loss: 1.3629 - val_mae: 1.3629\n",
      "Epoch 111/500\n",
      "2566/2566 [==============================] - 347s 135ms/step - loss: 1.3557 - mae: 1.3557 - val_loss: 1.3205 - val_mae: 1.3205\n",
      "Epoch 112/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.3486 - mae: 1.3486 - val_loss: 1.3011 - val_mae: 1.3011\n",
      "Epoch 113/500\n",
      "2566/2566 [==============================] - 49s 19ms/step - loss: 1.3355 - mae: 1.3355 - val_loss: 1.3455 - val_mae: 1.3455\n",
      "Epoch 114/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.3184 - mae: 1.3184 - val_loss: 1.2643 - val_mae: 1.2643\n",
      "Epoch 115/500\n",
      "2566/2566 [==============================] - 49s 19ms/step - loss: 1.3158 - mae: 1.3158 - val_loss: 1.2854 - val_mae: 1.2854\n",
      "Epoch 116/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.3172 - mae: 1.3172 - val_loss: 1.3205 - val_mae: 1.3205\n",
      "Epoch 117/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.3110 - mae: 1.3110 - val_loss: 1.2370 - val_mae: 1.2370\n",
      "Epoch 118/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.3020 - mae: 1.3020 - val_loss: 1.2786 - val_mae: 1.2786\n",
      "Epoch 119/500\n",
      "2566/2566 [==============================] - 49s 19ms/step - loss: 1.3039 - mae: 1.3039 - val_loss: 1.2807 - val_mae: 1.2807\n",
      "Epoch 120/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.2985 - mae: 1.2985 - val_loss: 1.2974 - val_mae: 1.2974\n",
      "Epoch 121/500\n",
      "2566/2566 [==============================] - 49s 19ms/step - loss: 1.2920 - mae: 1.2920 - val_loss: 1.3470 - val_mae: 1.3470\n",
      "Epoch 122/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.8953 - mae: 1.8953 - val_loss: 1.9511 - val_mae: 1.9511\n",
      "Epoch 123/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.8238 - mae: 1.8238 - val_loss: 1.8144 - val_mae: 1.8144\n",
      "Epoch 124/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.9681 - mae: 1.9681 - val_loss: 1.8295 - val_mae: 1.8295\n",
      "Epoch 125/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.7287 - mae: 1.7287 - val_loss: 1.6776 - val_mae: 1.6776\n",
      "Epoch 126/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.6559 - mae: 1.6559 - val_loss: 1.5844 - val_mae: 1.5844\n",
      "Epoch 127/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.6787 - mae: 1.6787 - val_loss: 1.6157 - val_mae: 1.6157\n",
      "Epoch 128/500\n",
      "2566/2566 [==============================] - 49s 19ms/step - loss: 1.5919 - mae: 1.5919 - val_loss: 1.6532 - val_mae: 1.6532\n",
      "Epoch 129/500\n",
      "2566/2566 [==============================] - 210s 82ms/step - loss: 1.5467 - mae: 1.5467 - val_loss: 1.5069 - val_mae: 1.5069\n",
      "Epoch 130/500\n",
      "2566/2566 [==============================] - 50s 20ms/step - loss: 1.5176 - mae: 1.5176 - val_loss: 1.4891 - val_mae: 1.4891\n",
      "Epoch 131/500\n",
      "2566/2566 [==============================] - 49s 19ms/step - loss: 1.4837 - mae: 1.4837 - val_loss: 1.4040 - val_mae: 1.4040\n",
      "Epoch 132/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.7035 - mae: 1.7035 - val_loss: 1.7327 - val_mae: 1.7327\n",
      "Epoch 133/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.6612 - mae: 1.6612 - val_loss: 1.5562 - val_mae: 1.5562\n",
      "Epoch 134/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.5713 - mae: 1.5713 - val_loss: 1.5417 - val_mae: 1.5417\n",
      "Epoch 135/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.5416 - mae: 1.5416 - val_loss: 1.6659 - val_mae: 1.6659\n",
      "Epoch 136/500\n",
      "2566/2566 [==============================] - 49s 19ms/step - loss: 1.5036 - mae: 1.5036 - val_loss: 1.5081 - val_mae: 1.5081\n",
      "Epoch 137/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.4649 - mae: 1.4649 - val_loss: 1.4798 - val_mae: 1.4798\n",
      "Epoch 138/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.4329 - mae: 1.4329 - val_loss: 1.3737 - val_mae: 1.3737\n",
      "Epoch 139/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.4082 - mae: 1.4082 - val_loss: 1.3606 - val_mae: 1.3606\n",
      "Epoch 140/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.5812 - mae: 1.5812 - val_loss: 1.6746 - val_mae: 1.6746\n",
      "Epoch 141/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.6247 - mae: 1.6247 - val_loss: 1.6077 - val_mae: 1.6077\n",
      "Epoch 142/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.5425 - mae: 1.5425 - val_loss: 1.5120 - val_mae: 1.5120\n",
      "Epoch 143/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.5018 - mae: 1.5018 - val_loss: 1.4862 - val_mae: 1.4862\n",
      "Epoch 144/500\n",
      "2566/2566 [==============================] - 47s 19ms/step - loss: 1.4725 - mae: 1.4725 - val_loss: 1.4443 - val_mae: 1.4443\n",
      "Epoch 145/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.4577 - mae: 1.4577 - val_loss: 1.4267 - val_mae: 1.4267\n",
      "Epoch 146/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.4347 - mae: 1.4347 - val_loss: 1.4424 - val_mae: 1.4424\n",
      "Epoch 147/500\n",
      "2566/2566 [==============================] - 44s 17ms/step - loss: 1.4284 - mae: 1.4284 - val_loss: 1.3676 - val_mae: 1.3676\n",
      "Epoch 148/500\n",
      "2566/2566 [==============================] - 45s 18ms/step - loss: 1.4135 - mae: 1.4135 - val_loss: 1.5331 - val_mae: 1.5331\n",
      "Epoch 149/500\n",
      "2566/2566 [==============================] - 43s 17ms/step - loss: 1.4053 - mae: 1.4053 - val_loss: 1.3909 - val_mae: 1.3909\n",
      "Epoch 150/500\n",
      "2566/2566 [==============================] - 44s 17ms/step - loss: 1.3914 - mae: 1.3914 - val_loss: 1.3963 - val_mae: 1.3963\n",
      "Epoch 151/500\n",
      "2566/2566 [==============================] - 43s 17ms/step - loss: 1.3816 - mae: 1.3816 - val_loss: 1.3414 - val_mae: 1.3414\n",
      "Epoch 152/500\n",
      "2566/2566 [==============================] - 44s 17ms/step - loss: 1.3732 - mae: 1.3732 - val_loss: 1.3419 - val_mae: 1.3419\n",
      "Epoch 153/500\n",
      "2566/2566 [==============================] - 44s 17ms/step - loss: 1.3689 - mae: 1.3689 - val_loss: 1.3624 - val_mae: 1.3624\n",
      "Epoch 154/500\n",
      "2566/2566 [==============================] - 44s 17ms/step - loss: 1.3674 - mae: 1.3674 - val_loss: 1.3237 - val_mae: 1.3237\n",
      "Epoch 155/500\n",
      "2566/2566 [==============================] - 44s 17ms/step - loss: 1.3862 - mae: 1.3862 - val_loss: 3.0305 - val_mae: 3.0305\n",
      "Epoch 156/500\n",
      "2566/2566 [==============================] - 44s 17ms/step - loss: 2.2480 - mae: 2.2480 - val_loss: 1.9013 - val_mae: 1.9013\n",
      "Epoch 157/500\n",
      "2566/2566 [==============================] - 43s 17ms/step - loss: 1.8408 - mae: 1.8408 - val_loss: 1.6938 - val_mae: 1.6938\n",
      "Epoch 158/500\n",
      "2566/2566 [==============================] - 45s 17ms/step - loss: 1.6950 - mae: 1.6950 - val_loss: 1.7417 - val_mae: 1.7417\n",
      "Epoch 159/500\n",
      "2566/2566 [==============================] - 44s 17ms/step - loss: 1.6333 - mae: 1.6333 - val_loss: 1.7363 - val_mae: 1.7363\n",
      "Epoch 160/500\n",
      "2566/2566 [==============================] - 44s 17ms/step - loss: 1.5945 - mae: 1.5945 - val_loss: 1.5895 - val_mae: 1.5895\n",
      "Epoch 161/500\n",
      "2566/2566 [==============================] - 44s 17ms/step - loss: 1.5913 - mae: 1.5913 - val_loss: 1.5685 - val_mae: 1.5685\n",
      "Epoch 162/500\n",
      "2566/2566 [==============================] - 45s 18ms/step - loss: 1.5484 - mae: 1.5484 - val_loss: 1.5239 - val_mae: 1.5239\n",
      "Epoch 163/500\n",
      "2566/2566 [==============================] - 43s 17ms/step - loss: 1.5202 - mae: 1.5202 - val_loss: 1.4812 - val_mae: 1.4812\n",
      "Epoch 164/500\n",
      "2566/2566 [==============================] - 44s 17ms/step - loss: 1.5039 - mae: 1.5039 - val_loss: 1.6800 - val_mae: 1.6800\n",
      "Epoch 165/500\n",
      "2566/2566 [==============================] - 45s 17ms/step - loss: 1.4903 - mae: 1.4903 - val_loss: 1.4574 - val_mae: 1.4574\n",
      "Epoch 166/500\n",
      "2566/2566 [==============================] - 44s 17ms/step - loss: 1.4746 - mae: 1.4746 - val_loss: 1.4574 - val_mae: 1.4574\n",
      "Epoch 167/500\n",
      "2566/2566 [==============================] - 44s 17ms/step - loss: 1.4665 - mae: 1.4665 - val_loss: 1.4166 - val_mae: 1.4166\n",
      "Epoch 168/500\n",
      "2566/2566 [==============================] - 50s 20ms/step - loss: 1.4516 - mae: 1.4516 - val_loss: 1.4198 - val_mae: 1.4198\n",
      "Epoch 169/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.4428 - mae: 1.4428 - val_loss: 1.4392 - val_mae: 1.4392\n",
      "Epoch 170/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.5236 - mae: 1.5236 - val_loss: 2.1433 - val_mae: 2.1433\n",
      "Epoch 171/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.7948 - mae: 1.7948 - val_loss: 1.6736 - val_mae: 1.6736\n",
      "Epoch 172/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.6367 - mae: 1.6367 - val_loss: 1.6182 - val_mae: 1.6182\n",
      "Epoch 173/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.5897 - mae: 1.5897 - val_loss: 1.5233 - val_mae: 1.5233\n",
      "Epoch 174/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.5561 - mae: 1.5561 - val_loss: 1.5097 - val_mae: 1.5097\n",
      "Epoch 175/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 17.0504 - mae: 17.0504 - val_loss: 3.3054 - val_mae: 3.3054\n",
      "Epoch 176/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 2.5477 - mae: 2.5477 - val_loss: 2.1829 - val_mae: 2.1829\n",
      "Epoch 177/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 2.1076 - mae: 2.1076 - val_loss: 2.0853 - val_mae: 2.0853\n",
      "Epoch 178/500\n",
      "2566/2566 [==============================] - 49s 19ms/step - loss: 1.9203 - mae: 1.9203 - val_loss: 1.7941 - val_mae: 1.7941\n",
      "Epoch 179/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.7786 - mae: 1.7786 - val_loss: 1.6815 - val_mae: 1.6815\n",
      "Epoch 180/500\n",
      "2566/2566 [==============================] - 49s 19ms/step - loss: 1.6932 - mae: 1.6932 - val_loss: 1.6399 - val_mae: 1.6399\n",
      "Epoch 181/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.6492 - mae: 1.6492 - val_loss: 1.5562 - val_mae: 1.5562\n",
      "Epoch 182/500\n",
      "2566/2566 [==============================] - 50s 19ms/step - loss: 1.6055 - mae: 1.6055 - val_loss: 1.5805 - val_mae: 1.5805\n",
      "Epoch 183/500\n",
      "2566/2566 [==============================] - 49s 19ms/step - loss: 1.5773 - mae: 1.5773 - val_loss: 1.5513 - val_mae: 1.5513\n",
      "Epoch 184/500\n",
      "2566/2566 [==============================] - 51s 20ms/step - loss: 1.5587 - mae: 1.5587 - val_loss: 1.4904 - val_mae: 1.4904\n",
      "Epoch 185/500\n",
      "2566/2566 [==============================] - 49s 19ms/step - loss: 1.5358 - mae: 1.5358 - val_loss: 1.4983 - val_mae: 1.4983\n",
      "Epoch 186/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.5148 - mae: 1.5148 - val_loss: 1.4785 - val_mae: 1.4785\n",
      "Epoch 187/500\n",
      "2566/2566 [==============================] - 49s 19ms/step - loss: 1.5004 - mae: 1.5004 - val_loss: 1.5121 - val_mae: 1.5121\n",
      "Epoch 188/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.7487 - mae: 1.7487 - val_loss: 1.6713 - val_mae: 1.6713\n",
      "Epoch 189/500\n",
      "2566/2566 [==============================] - 49s 19ms/step - loss: 1.5746 - mae: 1.5746 - val_loss: 1.4886 - val_mae: 1.4886\n",
      "Epoch 190/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.5079 - mae: 1.5079 - val_loss: 1.4365 - val_mae: 1.4365\n",
      "Epoch 191/500\n",
      "2566/2566 [==============================] - 49s 19ms/step - loss: 1.4548 - mae: 1.4548 - val_loss: 1.3997 - val_mae: 1.3997\n",
      "Epoch 192/500\n",
      "2566/2566 [==============================] - 49s 19ms/step - loss: 1.4218 - mae: 1.4218 - val_loss: 1.3848 - val_mae: 1.3848\n",
      "Epoch 193/500\n",
      "2566/2566 [==============================] - 49s 19ms/step - loss: 1.4070 - mae: 1.4070 - val_loss: 1.3881 - val_mae: 1.3881\n",
      "Epoch 194/500\n",
      "2566/2566 [==============================] - 49s 19ms/step - loss: 1.3957 - mae: 1.3957 - val_loss: 1.3679 - val_mae: 1.3679\n",
      "Epoch 195/500\n",
      "2566/2566 [==============================] - 49s 19ms/step - loss: 1.3810 - mae: 1.3810 - val_loss: 1.3789 - val_mae: 1.3789\n",
      "Epoch 196/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.3746 - mae: 1.3746 - val_loss: 1.3507 - val_mae: 1.3507\n",
      "Epoch 197/500\n",
      "2566/2566 [==============================] - 49s 19ms/step - loss: 1.3695 - mae: 1.3695 - val_loss: 1.4125 - val_mae: 1.4125\n",
      "Epoch 198/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.3588 - mae: 1.3588 - val_loss: 1.3000 - val_mae: 1.3000\n",
      "Epoch 199/500\n",
      "2566/2566 [==============================] - 50s 20ms/step - loss: 1.3544 - mae: 1.3544 - val_loss: 1.4477 - val_mae: 1.4477\n",
      "Epoch 200/500\n",
      "2566/2566 [==============================] - 49s 19ms/step - loss: 1.3454 - mae: 1.3454 - val_loss: 1.3474 - val_mae: 1.3474\n",
      "Epoch 201/500\n",
      "2566/2566 [==============================] - 50s 19ms/step - loss: 1.3447 - mae: 1.3447 - val_loss: 1.3552 - val_mae: 1.3552\n",
      "Epoch 202/500\n",
      "2566/2566 [==============================] - 49s 19ms/step - loss: 1.3424 - mae: 1.3424 - val_loss: 1.2882 - val_mae: 1.2882\n",
      "Epoch 203/500\n",
      "2566/2566 [==============================] - 49s 19ms/step - loss: 1.3367 - mae: 1.3367 - val_loss: 1.3546 - val_mae: 1.3546\n",
      "Epoch 204/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.3354 - mae: 1.3354 - val_loss: 1.3349 - val_mae: 1.3349\n",
      "Epoch 205/500\n",
      "2566/2566 [==============================] - 52s 20ms/step - loss: 1.3289 - mae: 1.3289 - val_loss: 1.3873 - val_mae: 1.3873\n",
      "Epoch 206/500\n",
      "2566/2566 [==============================] - 49s 19ms/step - loss: 1.3271 - mae: 1.3271 - val_loss: 1.2734 - val_mae: 1.2734\n",
      "Epoch 207/500\n",
      "2566/2566 [==============================] - 50s 19ms/step - loss: 1.3249 - mae: 1.3249 - val_loss: 1.3063 - val_mae: 1.3063\n",
      "Epoch 208/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.3195 - mae: 1.3195 - val_loss: 1.2744 - val_mae: 1.2744\n",
      "Epoch 209/500\n",
      "2566/2566 [==============================] - 50s 19ms/step - loss: 1.3152 - mae: 1.3152 - val_loss: 1.2817 - val_mae: 1.2817\n",
      "Epoch 210/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.3157 - mae: 1.3157 - val_loss: 1.2863 - val_mae: 1.2863\n",
      "Epoch 211/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.3140 - mae: 1.3140 - val_loss: 1.2976 - val_mae: 1.2976\n",
      "Epoch 212/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.3120 - mae: 1.3120 - val_loss: 1.2773 - val_mae: 1.2773\n",
      "Epoch 213/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.3083 - mae: 1.3083 - val_loss: 1.3033 - val_mae: 1.3033\n",
      "Epoch 214/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.3023 - mae: 1.3023 - val_loss: 1.3392 - val_mae: 1.3392\n",
      "Epoch 215/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.3035 - mae: 1.3035 - val_loss: 1.2752 - val_mae: 1.2752\n",
      "Epoch 216/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.3012 - mae: 1.3012 - val_loss: 1.2523 - val_mae: 1.2523\n",
      "Epoch 217/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.3020 - mae: 1.3020 - val_loss: 1.2814 - val_mae: 1.2814\n",
      "Epoch 218/500\n",
      "2566/2566 [==============================] - 46s 18ms/step - loss: 1.3003 - mae: 1.3003 - val_loss: 1.2719 - val_mae: 1.2719\n",
      "Epoch 219/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.2957 - mae: 1.2957 - val_loss: 1.2905 - val_mae: 1.2905\n",
      "Epoch 220/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.2954 - mae: 1.2954 - val_loss: 1.2907 - val_mae: 1.2907\n",
      "Epoch 221/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.2903 - mae: 1.2903 - val_loss: 1.2427 - val_mae: 1.2427\n",
      "Epoch 222/500\n",
      "2566/2566 [==============================] - 50s 20ms/step - loss: 1.2904 - mae: 1.2904 - val_loss: 1.2609 - val_mae: 1.2609\n",
      "Epoch 223/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.2883 - mae: 1.2883 - val_loss: 1.2705 - val_mae: 1.2705\n",
      "Epoch 224/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.2858 - mae: 1.2858 - val_loss: 1.2485 - val_mae: 1.2485\n",
      "Epoch 225/500\n",
      "2566/2566 [==============================] - 46s 18ms/step - loss: 1.2861 - mae: 1.2861 - val_loss: 1.3077 - val_mae: 1.3077\n",
      "Epoch 226/500\n",
      "2566/2566 [==============================] - 46s 18ms/step - loss: 1.2838 - mae: 1.2838 - val_loss: 1.2492 - val_mae: 1.2492\n",
      "Epoch 227/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.2795 - mae: 1.2795 - val_loss: 1.2495 - val_mae: 1.2495\n",
      "Epoch 228/500\n",
      "2566/2566 [==============================] - 46s 18ms/step - loss: 1.2788 - mae: 1.2788 - val_loss: 1.2396 - val_mae: 1.2396\n",
      "Epoch 229/500\n",
      "2566/2566 [==============================] - 49s 19ms/step - loss: 1.2781 - mae: 1.2781 - val_loss: 1.2394 - val_mae: 1.2394\n",
      "Epoch 230/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.2781 - mae: 1.2781 - val_loss: 1.2597 - val_mae: 1.2597\n",
      "Epoch 231/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.2746 - mae: 1.2746 - val_loss: 1.3626 - val_mae: 1.3626\n",
      "Epoch 232/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.6486 - mae: 1.6486 - val_loss: 2.0061 - val_mae: 2.0061\n",
      "Epoch 233/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.8442 - mae: 1.8442 - val_loss: 1.7019 - val_mae: 1.7019\n",
      "Epoch 234/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 2.0958 - mae: 2.0958 - val_loss: 1.9719 - val_mae: 1.9719\n",
      "Epoch 235/500\n",
      "2566/2566 [==============================] - 47s 19ms/step - loss: 1.7454 - mae: 1.7454 - val_loss: 1.7039 - val_mae: 1.7039\n",
      "Epoch 236/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.5804 - mae: 1.5804 - val_loss: 1.6494 - val_mae: 1.6494\n",
      "Epoch 237/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.5012 - mae: 1.5012 - val_loss: 1.4137 - val_mae: 1.4137\n",
      "Epoch 238/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.4481 - mae: 1.4481 - val_loss: 1.3756 - val_mae: 1.3756\n",
      "Epoch 239/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.4244 - mae: 1.4244 - val_loss: 1.4186 - val_mae: 1.4186\n",
      "Epoch 240/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.4068 - mae: 1.4068 - val_loss: 1.5130 - val_mae: 1.5130\n",
      "Epoch 241/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.3962 - mae: 1.3962 - val_loss: 1.3914 - val_mae: 1.3914\n",
      "Epoch 242/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.3848 - mae: 1.3848 - val_loss: 1.3587 - val_mae: 1.3587\n",
      "Epoch 243/500\n",
      "2566/2566 [==============================] - 50s 19ms/step - loss: 1.3722 - mae: 1.3722 - val_loss: 1.3779 - val_mae: 1.3779\n",
      "Epoch 244/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.3707 - mae: 1.3707 - val_loss: 1.3961 - val_mae: 1.3961\n",
      "Epoch 245/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.3632 - mae: 1.3632 - val_loss: 1.3977 - val_mae: 1.3977\n",
      "Epoch 246/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.3554 - mae: 1.3554 - val_loss: 1.4045 - val_mae: 1.4045\n",
      "Epoch 247/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.3493 - mae: 1.3493 - val_loss: 1.3721 - val_mae: 1.3721\n",
      "Epoch 248/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.3408 - mae: 1.3408 - val_loss: 1.3626 - val_mae: 1.3626\n",
      "Epoch 249/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.3380 - mae: 1.3380 - val_loss: 1.3017 - val_mae: 1.3017\n",
      "Epoch 250/500\n",
      "2566/2566 [==============================] - 46s 18ms/step - loss: 1.3258 - mae: 1.3258 - val_loss: 1.3184 - val_mae: 1.3184\n",
      "Epoch 251/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.3183 - mae: 1.3183 - val_loss: 1.3792 - val_mae: 1.3792\n",
      "Epoch 252/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.3177 - mae: 1.3177 - val_loss: 1.3478 - val_mae: 1.3478\n",
      "Epoch 253/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 2.0630 - mae: 2.0630 - val_loss: 1.6689 - val_mae: 1.6689\n",
      "Epoch 254/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.6437 - mae: 1.6437 - val_loss: 1.5654 - val_mae: 1.5654\n",
      "Epoch 255/500\n",
      "2566/2566 [==============================] - 85s 33ms/step - loss: 1.5714 - mae: 1.5714 - val_loss: 1.5741 - val_mae: 1.5741\n",
      "Epoch 256/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.5186 - mae: 1.5186 - val_loss: 1.4559 - val_mae: 1.4559\n",
      "Epoch 257/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.4580 - mae: 1.4580 - val_loss: 1.4345 - val_mae: 1.4345\n",
      "Epoch 258/500\n",
      "2566/2566 [==============================] - 46s 18ms/step - loss: 1.4386 - mae: 1.4386 - val_loss: 1.3899 - val_mae: 1.3899\n",
      "Epoch 259/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.4216 - mae: 1.4216 - val_loss: 1.3915 - val_mae: 1.3915\n",
      "Epoch 260/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.4055 - mae: 1.4055 - val_loss: 1.3637 - val_mae: 1.3637\n",
      "Epoch 261/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.3928 - mae: 1.3928 - val_loss: 1.3378 - val_mae: 1.3378\n",
      "Epoch 262/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.3984 - mae: 1.3984 - val_loss: 1.4203 - val_mae: 1.4203\n",
      "Epoch 263/500\n",
      "2566/2566 [==============================] - 46s 18ms/step - loss: 1.3726 - mae: 1.3726 - val_loss: 1.3241 - val_mae: 1.3241\n",
      "Epoch 264/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.3508 - mae: 1.3508 - val_loss: 1.3383 - val_mae: 1.3383\n",
      "Epoch 265/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.3422 - mae: 1.3422 - val_loss: 1.3313 - val_mae: 1.3313\n",
      "Epoch 266/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.3327 - mae: 1.3327 - val_loss: 1.3181 - val_mae: 1.3181\n",
      "Epoch 267/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.3187 - mae: 1.3187 - val_loss: 1.2736 - val_mae: 1.2736\n",
      "Epoch 268/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.3219 - mae: 1.3219 - val_loss: 1.3307 - val_mae: 1.3307\n",
      "Epoch 269/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.3106 - mae: 1.3106 - val_loss: 1.4026 - val_mae: 1.4026\n",
      "Epoch 270/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.3075 - mae: 1.3075 - val_loss: 1.2815 - val_mae: 1.2815\n",
      "Epoch 271/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.3029 - mae: 1.3029 - val_loss: 1.2916 - val_mae: 1.2916\n",
      "Epoch 272/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.3006 - mae: 1.3006 - val_loss: 1.2647 - val_mae: 1.2647\n",
      "Epoch 273/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.2931 - mae: 1.2931 - val_loss: 1.2551 - val_mae: 1.2551\n",
      "Epoch 274/500\n",
      "2566/2566 [==============================] - 49s 19ms/step - loss: 1.2928 - mae: 1.2928 - val_loss: 1.3354 - val_mae: 1.3354\n",
      "Epoch 275/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.2885 - mae: 1.2885 - val_loss: 1.2788 - val_mae: 1.2788\n",
      "Epoch 276/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.2878 - mae: 1.2878 - val_loss: 1.2528 - val_mae: 1.2528\n",
      "Epoch 277/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.2814 - mae: 1.2814 - val_loss: 1.2520 - val_mae: 1.2520\n",
      "Epoch 278/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.2825 - mae: 1.2825 - val_loss: 1.2701 - val_mae: 1.2701\n",
      "Epoch 279/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.3326 - mae: 1.3326 - val_loss: 1.3221 - val_mae: 1.3221\n",
      "Epoch 280/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.2834 - mae: 1.2834 - val_loss: 1.2586 - val_mae: 1.2586\n",
      "Epoch 281/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.2803 - mae: 1.2803 - val_loss: 1.2498 - val_mae: 1.2498\n",
      "Epoch 282/500\n",
      "2566/2566 [==============================] - 46s 18ms/step - loss: 1.2786 - mae: 1.2786 - val_loss: 1.2879 - val_mae: 1.2879\n",
      "Epoch 283/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.2727 - mae: 1.2727 - val_loss: 1.2347 - val_mae: 1.2347\n",
      "Epoch 284/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.2696 - mae: 1.2696 - val_loss: 1.4389 - val_mae: 1.4389\n",
      "Epoch 285/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.2700 - mae: 1.2700 - val_loss: 1.2783 - val_mae: 1.2783\n",
      "Epoch 286/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.2608 - mae: 1.2608 - val_loss: 1.2932 - val_mae: 1.2932\n",
      "Epoch 287/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.2717 - mae: 1.2717 - val_loss: 1.2893 - val_mae: 1.2893\n",
      "Epoch 288/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.2640 - mae: 1.2640 - val_loss: 1.2327 - val_mae: 1.2327\n",
      "Epoch 289/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.2629 - mae: 1.2629 - val_loss: 1.2510 - val_mae: 1.2510\n",
      "Epoch 290/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.2599 - mae: 1.2599 - val_loss: 1.2351 - val_mae: 1.2351\n",
      "Epoch 291/500\n",
      "2566/2566 [==============================] - 125s 49ms/step - loss: 1.2582 - mae: 1.2582 - val_loss: 1.2547 - val_mae: 1.2547\n",
      "Epoch 292/500\n",
      "2566/2566 [==============================] - 46s 18ms/step - loss: 1.2603 - mae: 1.2603 - val_loss: 1.2623 - val_mae: 1.2623\n",
      "Epoch 293/500\n",
      "2566/2566 [==============================] - 49s 19ms/step - loss: 1.2565 - mae: 1.2565 - val_loss: 1.2789 - val_mae: 1.2789\n",
      "Epoch 294/500\n",
      "2566/2566 [==============================] - 49s 19ms/step - loss: 1.2575 - mae: 1.2575 - val_loss: 1.2629 - val_mae: 1.2629\n",
      "Epoch 295/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.2576 - mae: 1.2576 - val_loss: 1.1993 - val_mae: 1.1993\n",
      "Epoch 296/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.2554 - mae: 1.2554 - val_loss: 1.2307 - val_mae: 1.2307\n",
      "Epoch 297/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.2520 - mae: 1.2520 - val_loss: 1.2798 - val_mae: 1.2798\n",
      "Epoch 298/500\n",
      "2566/2566 [==============================] - 50s 20ms/step - loss: 1.2538 - mae: 1.2538 - val_loss: 1.3093 - val_mae: 1.3093\n",
      "Epoch 299/500\n",
      "2566/2566 [==============================] - 53s 21ms/step - loss: 1.2507 - mae: 1.2507 - val_loss: 1.2979 - val_mae: 1.2979\n",
      "Epoch 300/500\n",
      "2566/2566 [==============================] - 50s 19ms/step - loss: 1.2484 - mae: 1.2484 - val_loss: 1.2247 - val_mae: 1.2247\n",
      "Epoch 301/500\n",
      "2566/2566 [==============================] - 52s 20ms/step - loss: 1.2503 - mae: 1.2503 - val_loss: 1.2120 - val_mae: 1.2120\n",
      "Epoch 302/500\n",
      "2566/2566 [==============================] - 60s 24ms/step - loss: 1.2493 - mae: 1.2493 - val_loss: 1.2309 - val_mae: 1.2309\n",
      "Epoch 303/500\n",
      "2566/2566 [==============================] - 51s 20ms/step - loss: 1.2476 - mae: 1.2476 - val_loss: 1.3377 - val_mae: 1.3377\n",
      "Epoch 304/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.2444 - mae: 1.2444 - val_loss: 1.2160 - val_mae: 1.2160\n",
      "Epoch 305/500\n",
      "2566/2566 [==============================] - 49s 19ms/step - loss: 1.2429 - mae: 1.2429 - val_loss: 1.2415 - val_mae: 1.2415\n",
      "Epoch 306/500\n",
      "2566/2566 [==============================] - 49s 19ms/step - loss: 1.2452 - mae: 1.2452 - val_loss: 1.2190 - val_mae: 1.2190\n",
      "Epoch 307/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.2452 - mae: 1.2452 - val_loss: 1.2128 - val_mae: 1.2128\n",
      "Epoch 308/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.2423 - mae: 1.2423 - val_loss: 1.2705 - val_mae: 1.2705\n",
      "Epoch 309/500\n",
      "2566/2566 [==============================] - 49s 19ms/step - loss: 1.2441 - mae: 1.2441 - val_loss: 1.2636 - val_mae: 1.2636\n",
      "Epoch 310/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.2384 - mae: 1.2384 - val_loss: 1.3038 - val_mae: 1.3038\n",
      "Epoch 311/500\n",
      "2566/2566 [==============================] - 54s 21ms/step - loss: 1.2453 - mae: 1.2453 - val_loss: 1.1954 - val_mae: 1.1954\n",
      "Epoch 312/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.2410 - mae: 1.2410 - val_loss: 1.2143 - val_mae: 1.2143\n",
      "Epoch 313/500\n",
      "2566/2566 [==============================] - 47s 18ms/step - loss: 1.2409 - mae: 1.2409 - val_loss: 1.2362 - val_mae: 1.2362\n",
      "Epoch 314/500\n",
      "2566/2566 [==============================] - 49s 19ms/step - loss: 1.2395 - mae: 1.2395 - val_loss: 1.2736 - val_mae: 1.2736\n",
      "Epoch 315/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.2379 - mae: 1.2379 - val_loss: 1.1816 - val_mae: 1.1816\n",
      "Epoch 316/500\n",
      "2566/2566 [==============================] - 52s 20ms/step - loss: 1.2405 - mae: 1.2405 - val_loss: 1.2522 - val_mae: 1.2522\n",
      "Epoch 317/500\n",
      "2566/2566 [==============================] - 53s 21ms/step - loss: 1.2376 - mae: 1.2376 - val_loss: 1.1992 - val_mae: 1.1992\n",
      "Epoch 318/500\n",
      "2566/2566 [==============================] - 52s 20ms/step - loss: 1.2355 - mae: 1.2355 - val_loss: 1.1931 - val_mae: 1.1931\n",
      "Epoch 319/500\n",
      "2566/2566 [==============================] - 49s 19ms/step - loss: 1.2352 - mae: 1.2352 - val_loss: 1.1968 - val_mae: 1.1968\n",
      "Epoch 320/500\n",
      "2566/2566 [==============================] - 48s 19ms/step - loss: 1.2343 - mae: 1.2343 - val_loss: 1.1943 - val_mae: 1.1943\n",
      "Epoch 321/500\n",
      "2566/2566 [==============================] - 54s 21ms/step - loss: 1.2379 - mae: 1.2379 - val_loss: 1.1880 - val_mae: 1.1880\n",
      "Epoch 322/500\n",
      "2566/2566 [==============================] - 50s 20ms/step - loss: 1.2356 - mae: 1.2356 - val_loss: 1.2518 - val_mae: 1.2518\n",
      "Epoch 323/500\n",
      "2566/2566 [==============================] - 56s 22ms/step - loss: 1.2331 - mae: 1.2331 - val_loss: 1.3526 - val_mae: 1.3526\n",
      "Epoch 324/500\n",
      "2566/2566 [==============================] - 50s 19ms/step - loss: 1.2298 - mae: 1.2298 - val_loss: 1.2180 - val_mae: 1.2180\n",
      "Epoch 325/500\n",
      "2566/2566 [==============================] - 50s 19ms/step - loss: 1.2307 - mae: 1.2307 - val_loss: 1.2832 - val_mae: 1.2832\n",
      "Epoch 326/500\n",
      "2566/2566 [==============================] - 53s 20ms/step - loss: 1.2292 - mae: 1.2292 - val_loss: 1.2766 - val_mae: 1.2766\n",
      "Epoch 327/500\n",
      "2566/2566 [==============================] - 70s 27ms/step - loss: 1.2301 - mae: 1.2301 - val_loss: 1.1926 - val_mae: 1.1926\n",
      "Epoch 328/500\n",
      "2566/2566 [==============================] - 98s 38ms/step - loss: 1.2294 - mae: 1.2294 - val_loss: 1.1731 - val_mae: 1.1731\n",
      "Epoch 329/500\n",
      "2566/2566 [==============================] - 72s 28ms/step - loss: 1.2244 - mae: 1.2244 - val_loss: 1.1899 - val_mae: 1.1899\n",
      "Epoch 330/500\n",
      "2566/2566 [==============================] - 66s 26ms/step - loss: 5.3755 - mae: 5.3755 - val_loss: 7.5110 - val_mae: 7.5110\n",
      "Epoch 331/500\n",
      "2566/2566 [==============================] - 74s 29ms/step - loss: 7.5213 - mae: 7.5213 - val_loss: 7.5114 - val_mae: 7.5114\n",
      "Epoch 332/500\n",
      "2566/2566 [==============================] - 64s 25ms/step - loss: 7.5231 - mae: 7.5231 - val_loss: 7.5141 - val_mae: 7.5141\n",
      "Epoch 333/500\n",
      "2566/2566 [==============================] - 103s 40ms/step - loss: 7.5280 - mae: 7.5280 - val_loss: 7.5115 - val_mae: 7.5115\n",
      "Epoch 334/500\n",
      "2566/2566 [==============================] - 104s 41ms/step - loss: 7.5316 - mae: 7.5316 - val_loss: 7.5260 - val_mae: 7.5260\n",
      "Epoch 335/500\n",
      "2566/2566 [==============================] - 96s 37ms/step - loss: 7.5347 - mae: 7.5347 - val_loss: 7.5330 - val_mae: 7.5330\n",
      "Epoch 336/500\n",
      "2566/2566 [==============================] - 101s 40ms/step - loss: 7.5302 - mae: 7.5302 - val_loss: 7.5129 - val_mae: 7.5129\n",
      "Epoch 337/500\n",
      "2566/2566 [==============================] - 82s 32ms/step - loss: 7.5313 - mae: 7.5313 - val_loss: 7.5123 - val_mae: 7.5123\n",
      "Epoch 338/500\n",
      "2566/2566 [==============================] - 88s 34ms/step - loss: 7.5327 - mae: 7.5327 - val_loss: 7.5737 - val_mae: 7.5737\n",
      "Epoch 339/500\n",
      "2566/2566 [==============================] - 76s 29ms/step - loss: 7.5313 - mae: 7.5313 - val_loss: 7.5134 - val_mae: 7.5134\n",
      "Epoch 340/500\n",
      "2566/2566 [==============================] - 79s 31ms/step - loss: 7.5333 - mae: 7.5333 - val_loss: 7.5626 - val_mae: 7.5626\n",
      "Epoch 341/500\n",
      "2566/2566 [==============================] - 81s 31ms/step - loss: 7.5310 - mae: 7.5310 - val_loss: 7.5178 - val_mae: 7.5178\n",
      "Epoch 342/500\n",
      "2566/2566 [==============================] - 76s 30ms/step - loss: 7.5325 - mae: 7.5325 - val_loss: 7.5127 - val_mae: 7.5127\n",
      "Epoch 343/500\n",
      "2566/2566 [==============================] - 80s 31ms/step - loss: 7.5316 - mae: 7.5316 - val_loss: 7.5185 - val_mae: 7.5185\n",
      "Epoch 344/500\n",
      "2566/2566 [==============================] - 79s 31ms/step - loss: 7.5334 - mae: 7.5334 - val_loss: 7.5410 - val_mae: 7.5410\n",
      "Epoch 345/500\n",
      "2566/2566 [==============================] - 80s 31ms/step - loss: 7.5315 - mae: 7.5315 - val_loss: 7.5114 - val_mae: 7.5114\n",
      "Epoch 346/500\n",
      "2566/2566 [==============================] - 85s 33ms/step - loss: 7.5325 - mae: 7.5325 - val_loss: 7.5117 - val_mae: 7.5117\n",
      "Epoch 347/500\n",
      "2566/2566 [==============================] - 77s 30ms/step - loss: 7.5331 - mae: 7.5331 - val_loss: 7.5121 - val_mae: 7.5121\n",
      "Epoch 348/500\n",
      "2566/2566 [==============================] - 74s 29ms/step - loss: 7.5314 - mae: 7.5314 - val_loss: 7.5108 - val_mae: 7.5108\n",
      "Epoch 349/500\n",
      "2566/2566 [==============================] - 74s 29ms/step - loss: 7.5324 - mae: 7.5324 - val_loss: 7.5466 - val_mae: 7.5466\n",
      "Epoch 350/500\n",
      "2566/2566 [==============================] - 71s 28ms/step - loss: 7.5332 - mae: 7.5332 - val_loss: 7.5327 - val_mae: 7.5327\n",
      "Epoch 351/500\n",
      "2566/2566 [==============================] - 76s 30ms/step - loss: 7.5313 - mae: 7.5313 - val_loss: 7.5187 - val_mae: 7.5187\n",
      "Epoch 352/500\n",
      "2566/2566 [==============================] - 83s 32ms/step - loss: 7.5328 - mae: 7.5328 - val_loss: 7.5127 - val_mae: 7.5127\n",
      "Epoch 353/500\n",
      "2566/2566 [==============================] - 83s 32ms/step - loss: 7.5331 - mae: 7.5331 - val_loss: 7.5163 - val_mae: 7.5163\n",
      "Epoch 354/500\n",
      "2566/2566 [==============================] - ETA: 0s - loss: 7.5325 - mae: 7.5325"
     ]
    }
   ],
   "source": [
    "#Train the model\n",
    "#%%time\n",
    "history = dnn_new_all_model7.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    verbose=1, epochs=500,\n",
    "    batch_size = 500,\n",
    "    callbacks=get_callbacks(\"dnn_all_var_large_5layer_ep500_selu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c48973c57606234e133a66cdcf934be3996b888f1f158ed330e53f59eb9f4535"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
